{"text":"\n\nChapter 5 Testing tools and measurement \nManual testing \nManual testing is a type of software testing where a tester checks the software \nmanually—without using any automation tools—to find defects and ensure the \napplication works as expected. In this method, the tester acts like an end user and \nverifies features by executing test cases step by step. \nLimitations of Manual Testing \n1. Time-consuming- Manual testing takes a lot of time, especially for large \napplications. \n2. Not suitable for repetitive testing- Repeating the same test cases again \nand again (like regression testing) is boring and inefficient. \n3. Less accuracy -Human  errors  may  occur  while  executing  test  cases \nmanually. \n4. Limited test coverage - It  is  difficult  to  test  all  possible  inputs  and \nscenarios manually. \n5. Requires more manpower- More  testers  are  needed,  which  increases \nproject cost. \n6. Not reliable for performance testing- Manual  testing  cannot  measure \nload, stress, or performance accurately. \n7. Slow execution- Compared  to  automation,  manual  execution  is much \nslower. \n8. Difficult for large projects- Managing and executing test cases manually \nis hard in complex systems. \nManual Testing Process (Steps) \n \n \n\n1. Requirement Analysis \n Understand software requirements (SRS, user stories). \n Identify what needs to be tested. \n Clarify doubts with developers or clients. \n2. Test Planning \n Decide the test strategy and scope. \n Identify resources, tools (if any), and timelines. \n Prepare the test plan document. \n3. Test Case Design \n Write test cases based on requirements. \n Prepare test scenarios and test data. \n Review test cases for accuracy. \n4. Test Environment Setup \n Set up hardware and software needed for testing. \n Verify that the test environment is ready. \n5. Test Execution \n Execute test cases manually. \n Compare actual results with expected results. \n Mark test cases as Pass / Fail. \n6. Defect Reporting \n Report defects found during testing. \n Log defects in a defect tracking tool. \n Assign severity and priority. \n7. Re-testing and Regression Testing \n Re-test after defects are fixed. \n Perform regression testing to ensure existing functionality still works. \n8. Test Closure \n Prepare test summary report. \n Analyze test results. \n Sign off testing activities. \n\nAutomation Testing \nAutomation  Testing means  using  tools  like Selenium,  QTP/UFT,  TestNG, \nJUnit etc.  to  automatically  run  test  scripts  and  compare  expected  results  with \nactual results. Automation testing is a software testing technique in which test \ncases are executed automatically using testing tools and scripts \nExample: \nAutomatically testing login functionality multiple times with different inputs. \nBenefits of automated testing \n• faster than the manual testing \n• It is mostly used for regression testing \n• Reliable in results \n• Running test anytime, anywhere \n• Saves Time and Cost \n• Improves accuracy \n• Better quality software \n• Increases Efficiency \n• Better speed in executing tests \n• Re-usable  \n• More cycle of execution can be achieved through automation \nwhy Automation Testing is important? \n• Running Tests 24/7 \n• Fewer Human Resources \n• Reusability \n• Bugs \n• Reliability \nProcess of automation testing \n \n\n1. Test Automation Feasibility Analysis \nIn this step, we decide whether automation testing is suitable or not. \n Identify test cases that can be automated \n Check application stability \n Analyze cost, time, and ROI (Return on Investment) \n2.Appropriate Tool Selection \nHere, a suitable automation tool is selected based on: \n Type of application (web, mobile, desktop) \n Technology used \n Budget and license cost \n Team skill set \n Example: Selenium, UFT, TestComplete \n3.Evaluate the Suitable Framework \nIn this step, the automation framework is selected. \n Data-driven framework \n Keyword-driven framework \n Hybrid frame work \n Framework helps in reusability, maintainability, and reporting. \n4.Build the Proof of Concept (POC) \nA small automation sample is created to: \n Check tool capability \n Verify framework suitability \n Identify challenges early \n POC helps confirm that automation is feasible for the project. \n5.Develop Automation Framework \nA complete automation framework is designed, including: \n Test scripts structure \n Reusable functions \n Reporting mechanism \n Error handling \n This framework supports smooth automation execution. \n\n6. Develop Test Script, Execute and Analyze \n Write automation test scripts \n Execute scripts on test environment \n Analyze test results \n Identify failures and defects \n Reports are generated for better analysis. \nSoftware Testing Tools \n1. Manual Testing Tools \nUsed for test management and defect tracking: \n JIRA \n Bugzilla \n TestLink \n Mantis \n2.Automation Testing Tools \nUsed to automate functional testing: \n Selenium \n UFT (QTP) \n TestComplete \n Cypress \n3.Performance Testing Tools \nUsed to test load, speed, and stress: \n JMeter \n LoadRunner \n Gatling \n4.Mobile Testing Tools \nUsed for mobile applications: \n Appium \n Espresso \n XCUITest \n \n\n5. API Testing Tools \nUsed to test web services: \n Postman \n SoapUI \n Rest Assured \n6. Security Testing Tools \nUsed to find security vulnerabilities: \n OWASP ZAP \n Burp Suite \nComparison Between Automation testing and Manual Testing \nAspect  Manual Testing Automation Testing \nExecution \nPerformed   manually   by   a \nhuman  tester,  simulating  an \nend-user's actions. \nExecuted   automatically   using \nsoftware  tools  and  pre-written \nscripts. \nSpeed \nSlower     and     more     time-\nconsuming,    especially    for \nrepetitive tasks. \nSignificantly   faster   and   more \nefficient, running tests at \nmachine speed. \nAccuracy \nProne to human error, \nparticularly  during  repetitive \ntasks. \nHighly  consistent,  reliable,  and \nless   error-prone   as   tests   run \nidentically every time. \nCost \nLower  initial  setup  cost,  but \nhigher  long-term  cost  due  to \nhuman effort. \nHigher   initial   investment   for \ntools and script development, but \nmore  cost-effective  in  the  long \nrun. \nFlexibility \nHighly  adaptable;  testers  can \nadjust  their  approach  on  the \nfly and use intuition. \nLess   flexible;   requires   script \nupdates    for changes    in    the \napplication's UI or functionality. \nProgramming \nKnowledge \nNo  programming  knowledge \nis     required;     focuses     on \nRequires programming \nknowledge  (e.g.,  Python,  Java, \n\nproduct  knowledge  and  user \nexperience. \nJavaScript) to write and maintain \ntest scripts. \nBest Use Cases \nExploratory,    usability,    ad-\nhoc,    and    UI/UX    testing, \nwhere   human   judgment   is \ncrucial. \nRepetitive, data-intensive, \nperformance   (load/stress),   and \nregression testing. \nScalability \nLimited   scalability   as   it   is \nconstrained by human \nresources and time. \nHighly scalable; can run \nthousands of tests \nsimultaneously   across   various \nplatforms. \nSelecting a testing tool \n• Selecting the testing tools is an important of test automation for following \nreasons: \n1. Free tool are not well supported  \n2. Test tool sold by vendors are expensive \n3. Test tool require strong training \n4. Test tools generally do not meet all the requirement for automation \n5.  Not all test tools run on all platforms. \n6. Selecting a tool which is affordable \n7. Match the tool to its appropriate use \n8. Select a tool to its appropriate SDLC phase  \nCriteria for Selecting Test Tools \nSelecting  a  test  tool  is  important  to  ensure  effective  and  efficient  testing.  The \nfollowing criteria are considered while selecting a test tool: \n1. Meeting Requirements \n The selected test tool must meet the testing requirements of the project. \n Tool should support required types of testing \n(functional, regression, performance, etc.) \n It should align with project goals and scope \n\n Must support required test environments \nExample: \nIf the requirement is frequent regression testing of a web application, Selenium \nis suitable as it supports automated regression testing. \n2. Technology Expectations \n The  tool  should  be compatible  with  the  technology  used  in  the \napplication. \n Supports programming languages used in the project \n Works with required operating systems and browsers \n Compatible with databases, frameworks, and CI/CD tools \nExample: \nFor a Java-based web application running on Chrome and Firefox, Selenium with \nJava meets technology expectations. \n3. Training and Skill \n The testing team should have adequate knowledge and skills to use the \ntool. \n Learning curve should be reasonable \n Availability of training materials and documentation \n Skill level of testers should match tool complexity \nExample: \nIf  testers  are  beginners,  tools  like  Postman  are  easier  to  learn  than  complex \nscripting tools. \n4. Management Aspects \n Management-related factors play a key role in tool selection. \n Cost and licensing of the tool \n Time required for implementation \n Return on Investment (ROI) \n Support and maintenance effort \n \n\nExample: \nOpen-source tools like Selenium reduce licensing cost and are preferred when the \nbudget is limited. \nSelenium \nSelenium is  an open-source  automation  testing  tool used  to  automate web \napplications. It    supports    multiple browsers, operating    systems,    and \nprogramming  languages. Selenium  helps  testers automatically  execute  test \ncases instead of testing web applications manually. \nSelenium supports: \n Browsers: Chrome, Firefox, Edge, Safari \n Languages: Java, Python, C#, Ruby \n Platforms: Windows, Linux, macOS \n \nFeatures of Selenium \n1. Open Source \n Selenium is free to use. \n No license or subscription cost. \n2. Cross-Browser Testing \n Supports multiple browsers like Chrome, Firefox, Edge, Safari. \n Same test script can run on different browsers. \n \n\n3. Multi-Language Support \n Supports programming languages such as: \no Java \no Python \no C# \no Ruby \n Testers can choose any supported language. \n4. Platform Independent \n Works on Windows, Linux, and macOS. \n Tests can be executed on different operating systems. \n5. Supports Automation Frameworks \n Compatible with frameworks like: \no TestNG \no JUnit \no Cucumber \n Helps in data-driven and keyword-driven testing. \n6. Parallel Test Execution \n Supports running multiple test cases at the same time. \n Saves testing time. \n7. Integration with Third-party Tools \n Integrates with Jenkins, Maven, Git. \n Useful for continuous testing. \n8. Record and Playback (Selenium IDE) \n Selenium IDE allows recording and replaying test cases. \n Useful for beginners. \nComponents of Selenium \nSelenium is not a single tool. It is a product suite of software consisting of \nthe following components:  \n\n \n1. Selenium IDE \nSelenium IDE is a record-and-playback tool mainly used by beginners. It allows \ntesters to record user actions in the browser and replay them as test cases. It is \nuseful    for    creating    quick    automation    scripts    without    much    coding. \nExample: A tester  records steps for opening a website, entering username and \npassword,  and  clicking  the  login  button.  The  recorded  script  is  then  played  to \nverify the login function. \n2. Selenium WebDriver \nSelenium WebDriver is the core component of Selenium and is widely used in \nreal  projects.  It  directly  communicates  with  the  browser  and  supports  multiple \nprogramming languages like Java, Python, and C#. WebDriver is fast, reliable, \nand suitable for complex automation testing. \nExample: Using  Java  WebDriver  code  to  open  a  browser,  enter  login  details, \nclick submit, and verify that the homepage is displayed. \n3. Selenium Grid \nSelenium Grid is used to execute test cases on multiple machines, browsers, \nand  operating  systems  simultaneously.  It  helps  reduce  execution  time  and \nsupports cross-browser testing. \nExample: Running the same login test at the same time on Chrome in Windows \nand Firefox in Linux using Selenium Grid. \n4. Selenium RC (Remote Control) \nSelenium  RC  was  an  older  Selenium  component  used  before  WebDriver.  It \nworked  by  injecting  JavaScript  into  the  browser  to  control  it. However,  it  was \nslower and more complex, so it has been deprecated and replaced by WebDriver. \n\nExample: Earlier, Selenium RC was used to automate browser actions, but now \nWebDriver performs the same tasks more efficiently. \nSelenium IDE \nSelenium  IDE  (Integrated  Development  Environment) is  a record  and \nplayback  tool used  to  create  and  execute automation  test  cases  for  web \napplications. It works as a browser extension (Chrome / Firefox) and is mainly \nuseful for quick test creation. \nWhy Selenium IDE is Used  \n1. Easy to use – No programming knowledge is required. \n2. Record and playback feature – Automatically records user actions and \nreplays them. \n3. Fast test creation – Test cases can be created quickly. \n4. Beginner friendly – Best tool for learning Selenium automation. \n5. Supports quick testing – Useful for smoke and sanity testing. \n6. Debugging support – Helps identify errors in test steps. \n7. Free and open source – No license cost. \nSelenium IDE Components \n \n Menu  Bar:  Located  at  the  top,  the  menu  bar  contains  options  for  managing \nprojects and settings, such as creating new projects, opening existing ones, saving \ntests, and managing add-ons and preferences. \n Toolbar:  The  toolbar  provides  controls  for  test  case  execution  and  debugging. \nKey features include buttons to control execution speed, run the current test or all \ntests,  pause/resume  execution,  step  through  commands  one  by  one,  and  toggle \nrecording. \n\n Address Bar (Base URL Bar): This bar displays the root URL of the application \nbeing tested and remembers previously used URLs for easy navigation. \n Test  Case  Pane:  This  panel  lists  all  the  test  cases  within  the  current  project, \nallowing users to switch between them easily. \n Test  Script  Editor  Box:  This  central  area  displays  the  recorded  or  manually \ncreated test steps using commands. It has three main columns for each action: \no Command: The action to be performed (e.g., click, type, open, verifyText). \no Target: The web element on which the action is performed (e.g., using ID, name, \nXPath, or CSS selector). \no Value: Any input value or parameter required for the command (e.g., the text to \nbe typed into a field). \n Log and Reference Pane: This area is a tabbed panel at the bottom that provides \nimportant information during and after test execution: \no Log: Displays real-time messages, including info, errors, and warnings, showing \nwhether each step passed or failed. \no Reference: When  a  specific  command  is  selected  in  the  Test  Cases  Pane,  the \nReference  Pane  provides  a  brief  description,  usage  guidelines,  and  command-\nspecific information  \nLimitations of Selenium IDE \n1. Limited to simple test cases- Selenium IDE is suitable only for small and \nsimple test scenarios. \n2. Not suitable for complex applications- It cannot handle complex logic, \nloops, or conditions effectively. \n3. Limited programming support- Advanced  scripting  and  customization \nare difficult. \n4. No support for data-driven testing- Handling large test data is limited. \n5. Browser dependency - Works   mainly   as   a   browser   extension \n(Chrome/Firefox). \n6. Limited reporting features- Detailed  and  customized  reports  are  not \navailable. \n7. Poor scalability -Not  suitable  for  large  test  suites  or  enterprise-level \nprojects. \n8. Maintenance issues -Recorded scripts break easily if the UI changes. \n\nSelenium WebDriver \nSelenium WebDriver is the most important component of Selenium used \nfor automating web applications. It   is   an open-source   automation \nframework that directly communicates with the web browser and controls it \nto execute test cases just like a real user. WebDriver does not use record and \nplayback.  it uses programming code to interact with web elements, making \nit suitable for complex and large-scale automation projects. \nArchitecture of Selenium WebDriver \nThe architecture   of   Selenium   WebDriver explains   how   a   test   script \ncommunicates   with   the   browser   to   automate   web   applications.   Selenium \nWebDriver follows a client–server architecture. \n \n \nThe four key components that work together are: \n Selenium  Client  Libraries  (Language  Bindings):  These  are  the  language-\nspecific libraries (e.g., Java, Python, C#, Ruby) that allow you to write test scripts \nin your preferred programming language. They provide the APIs for interacting \nwith the WebDriver. \n WebDriver  W3C  Protocol:  This  standardized  wire  protocol,  adopted  as  the \ndefault in Selenium 4, defines a set of commands and responses using JSON over \nHTTP. It acts as the communication interface, sending commands from the client \nto  the  browser  driver  and  receiving  responses.  (In  Selenium  3  and  earlier,  the \nJSON Wire Protocol was used as a non-standardized intermediary). \n\n Browser   Drivers:   Each   browser   has   a   specific,   standalone   driver   (e.g., \nChromeDriver,  GeckoDriver)  managed  by  its  respective  vendor.  The  driver \nreceives HTTP requests from the client, interprets the commands, and executes \nthe actions on the actual browser using the browser's native automation APIs. It \nalso receives the execution status and sends an HTTP response back to the client. \n Real  Browsers:  These  are  the  actual  web  browsers  (e.g.,  Google  Chrome, \nMozilla  Firefox,  Microsoft  Edge,  Safari)  where  the  automated  test  steps  are \nperformed, such as navigating to a URL, clicking elements, and entering text.  \nHow Selenium WebDriver Works \n1. A test script is written using a Selenium client library in a chosen language (e.g., \nJava). \n2. When  the  script  is  executed,  the  client  library  converts  the  commands  into  an \nHTTP request following the W3C WebDriver Protocol. \n3. This HTTP request is sent to the respective browser driver (which runs an HTTP \nserver). \n4. The browser driver interprets the request and communicates with the real browser \nusing the browser's native APIs to perform the specified actions. \n5. The  browser  executes  the  command  and  sends  the  result  or  status  back  to  the \nbrowser driver. \n6. The  driver  sends  an  HTTP  response  back  to  the  client  library,  which  then \nprocesses the result and continues with the next command in the script. \nSimple Example of Selenium WebDriver Architecture \nExample Scenario \nTest case: Open Google website in Chrome browser \nStep-by-Step Working \n1. Test Script \nThe tester writes a small program in Java: \ndriver.get(\"https://www.google.com\"); \nThis line means: “Open Google website.” \n\n2. Selenium WebDriver API \n WebDriver API receives the command from the test script. \n It converts this command into a standard request. \nActs as a translator between your code and the browser. \n3. Browser Driver (ChromeDriver) \n ChromeDriver receives the command from WebDriver API. \n It understands how to control the Chrome browser. \nActs like a remote control for Chrome. \n4. Real Browser (Chrome) \n Chrome browser opens. \n Google website is loaded on the screen. \nSoftware Testing Metrics and measurement \nMetrics can be defined as “STANDARDS OF MEASUREMENT”. Software \nTesting  Metrics  are  the  quantitative  measures  used  to  estimate  the  progress, \nquality,  productivity  and  health  of  the  software  testing  process.  The  goal  of \nsoftware  testing  metrics  is  to  improve  the  efficiency  and  effectiveness  in  the \nsoftware  testing  process  and  to  help  make  better  decisions  for  further  testing \nprocess by providing reliable data about the testing process. Software Metrics are \nused to measure the quality of the project. \nSoftware  test measurement  is  the  quantitative  indication  of  extent,  capacity, \ndimension, amount or size of some attribute of a process or product. \nSuppose, in general, “Kilogram” is a metric for measuring the attribute “Weight”. \nSimilarly, in software, “How many issues are found in a thousand lines of code?”, \nhere  No. of  issues  is  one  measurement  &  No.  of  lines  of  code  is  another \nmeasurement. Metric is defined from these two measurements. \nTest metrics example: \n1 How many defects exist within the module? \n2 How many test cases are executed per person? \n3 What is Test coverage %? \n \n\nTypes of Metrics \n \n1. Product Metrics \nProduct metrics measure the quality of the software product. These metrics focus \non defects, reliability, and performance of the final product. \n Defect Density - Number of defects found per size of software (e.g., per \n1000 lines of code). \n           Formula: \n              Defect Density = Total Defects / Size of Software \n           Example: \nTotal defects = 40 \nSoftware size = 8000 lines \n          Defect Density = 40 / 8 = 5 defects per 1000 lines \n          Higher defect density = Lower quality \n Defect Severity Distribution- Measures how serious the defects are. \n           Types of severity: \nCritical – System crash \nHigh – Major function not working \nMedium – Minor issue \nLow – UI issue \n        If many defects are critical → product quality is poor. \n Defect Leakage - Defects missed during testing but found after release. \n           Formula: \n            Defect Leakage = (Defects found after release / Total defects) × 100 \n             Lower leakage = Better testing quality \n\n Customer  Reported  Defects- Number  of  defects  reported  by  customers \nafter release. \n           More customer defects → Poor product quality. \n2. Process Metrics \nProcess  metrics  measure  the efficiency  and  effectiveness  of  the  testing \nprocess. \n Test Case Execution Rate- Measures percentage of test cases executed. \n          Formula: \n            Execution Rate = (Executed Test Cases / Total Test Cases) × 100 \n             Example: \nTotal test cases = 200 \nExecuted = 150 \n        Execution Rate = 75% \n Test Coverage- Measures how much of the application is tested. \n            Example: \n100 requirements \n90 tested \n          Coverage = 90% \n Defect Removal Efficiency (DRE)- Measures how effectively defects are \nremoved before release. \n          Formula: \n          DRE = (Defects found before release / Total defects) × 100 \n           Example: \nBefore release = 80 \nAfter release = 20 \n         DRE = 80% \n         Higher DRE = Better testing process \n Defect Detection Percentage (DDP)- Measures percentage of defects found \nduring testing. \n \n \n\n3. Project Metrics \n    Project metrics measure overall project performance. They focus on cost, time, \nand resources. \n Test Effort- Total time spent on testing. \n           Example: \n           Testing took 400 hours \n Schedule Variance-  Difference between planned time and actual time. \n           If actual time > planned time → Project delay \n Cost of Testing- Total money spent on testing activities. \n Productivity-  Work done per tester. \n            Example: \nTest cases written per day \nDefects found per tester \n "}